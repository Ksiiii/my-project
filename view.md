# 螺栓拧紧工艺智能助手：研究路线与阶段总结（对话全量要点版）
> 目标：把我们所有对话里与你科研相关的关键信息（背景、任务定义、数据版本演化、你尝试的改进、WP0–WP2 主线、当前进度与下一步）汇总成一份可直接继承的上下文文档。  
> 说明：不包含代码修改细节、环境配置与命令行操作；仅保留科研内容与实验协议层面的信息，确保新对话只读本文即可理解你的课题与现状。

---

## 0. 你现在的课题一句话定义
你在做的是：**在 VDI2230 解析模型强先验主导的螺栓连接/拧紧任务中，构建“解析基线 + 残差学习 + 约束一致性 + 严谨评测协议”的可复现研究范式（PITT-Bolt），并为未来 Bolt-BERT 式表格预训练与 Agent 闭环打基础。**

---

## 1. 工程意义与研究动机（你为什么要做、研究点在哪里）
### 1.1 工程侧
- 螺栓拧紧是典型装配工艺：输入（几何、材料、摩擦、预紧/扭矩/转角等）→ 输出（预紧力/夹紧力/安全裕度/失效风险等）。
- 现实中摩擦不确定、接触非线性、工艺扰动导致解析模型与真实系统存在系统偏差，工程需要“能用、稳、可解释、可控风险”的预测与决策支持。

### 1.2 研究侧
- 你的任务属于**结构化表格学习 + 强解析先验**：  
  解析模型（VDI2230）能算“近似正确”，但真实/仿真/测量会偏离它。
- 研究价值不在“再训练一个黑箱拟合器”，而在于提出并验证：  
  1) **解析基线 + 残差建模**（把学习难度集中到“偏差”上）  
  2) **物理约束一致性**（软/硬约束可消融）  
  3) **IID + OOD + 稳定性 + 违反率**的评测协议（让结论可验证、可复现）

---

## 2. 你目前的研究路线框架：WP0–WP2（重点）
> WP = Work Package（工作包），是把研究拆成可交付、可验收阶段的常见组织方式。  
> 为什么从 WP0 开始：因为你需要先“固化基准协议”，否则后续所有创新都容易返工或无法说服评审。

### WP0：任务与数据协议固化（Benchmark 化）
**目标**：任何人拉下仓库、使用同一数据版本与同一切分/指标协议，都能复现实验结果与结论。  
核心包含：
1) **数据字典固化**：每个字段含义、单位、取值范围、可行域（哪些是物理必然、哪些是工程经验）。
2) **切分（split）固化**：明确 train/val/test 的生成方式与随机种子（seed）；避免“每次切分不同导致结论漂移”。  
   - 你当前的典型规模：n_total=10000；test=0.2 → 2000；train/val=6400/1600（val 在 trainval 中再切 0.2）。
3) **评测与输出固化**：统一计算指标、统一输出到**summary.csv**（或同等统一表），并生成可追踪 run_id。

> 你最关心的“Benchmark 协议固化”的本质：  
> **把数据版本、切分、指标、输出格式统一成一个不可随意更改的标准**，让之后任何新模型/新方法都只改“模型”，不改“比较基准”。

---

### WP1：PITT v2（解析基线 + 残差学习 + 约束一致性）
**目标**：形成能命名、能消融、能解释的方法贡献，而不是“调参调出来的效果”。  
你路线的核心思想已经明确为：
- **不要直接学 FM**（这一步在 v01 上确实容易崩、也难解释），而是进入“物理一致的中间空间”学习。
- 典型形式（你已认同的主线）：
  - 先用解析模型给出基线：例如 \(k_{\text{vdi}}\)
  - 学习残差：\(g_\theta(x)\approx \Delta k\)
  - 得到：\(\hat{k}=k_{\text{vdi}}+g_\theta(x)\)
  - 再映射回工程量：\(\hat{FM}=\hat{k}\cdot F_{\text{proof}}\)

**约束一致性**（你明确问过软/硬约束含义）：
- 软约束：把可行域超界写进 loss 惩罚项（可调权重，适合做消融）
- 硬约束：输出投影/截断/参数化保证必在可行域（实现简单，但可能引入偏差，需要讨论）

> 你目前的直觉已经非常关键：  
> **预测 FM 崩并不意味着路线错，而是说明目标空间选得不对**。把学习目标换成中间量/残差，是更“物理先验 + 可解释”的路线。

---

### WP2：鲁棒性与可靠性评测（OOD + 稳定性 + 风险控制）
**目标**：回答两个评审会问的问题：  
1) 既然 GBDT 很强，你的深度方法为什么有必要？  
2) 你的方法在分布变化/噪声变化下是否更稳、更可信？

WP2 的关键组成：
- **OOD 设计**：至少两类  
  - 范围外推（range shift）  
  - 组合外推（combinatorial shift）  
  -（加分）噪声机制变化（noise mechanism shift）
- **多 seed 稳定性**：同一协议下跑多个随机种子，汇总均值与方差（让结论不依赖“碰巧的切分/初始化”）。
- **风险指标**：违反率（输出落在不可行域的比例）、过紧/欠紧比例（你已经在 summary 指标里出现 under_tight_ratio / over_tight_ratio 的思路）。

---

## 3. 数据与任务演化：为什么你会从 v01 走到 v02
你经历了一个非常典型的“研究路线校正”过程：

### 3.1 v01：直接预测 FM 的冲击
- 你做了 baseline：GBDT vs FT-Transformer
- 观察到：
  - **GBDT 在 VDI2230 合成数据上非常强**（几乎重建解析公式）
  - **FT-Transformer（off-the-shelf）在直接回归 FM 时表现很差**（甚至出现 R² 负、接近常数模型）
- 这让你产生质疑（训练很快、结果很快是否“不像科研”），但后来你逐渐意识到：  
  快并不等于不科研，关键是**协议是否严谨、评测是否全面、贡献是否清晰**。

### 3.2 v02：加入中间量，转向“中间空间/残差学习”
- 你更新数据集为 data/02：加入更适合学习的中间量（如 \(k_{\text{meas}}, k_{\text{vdi}}, \Delta k\) 等）
- 并且改变评价逻辑：  
  即使模型预测的是中间量，也统一映射回 FM 空间，计算工程指标（MAE/RMSE/R²、within_5%、within_10%、过紧/欠紧比例等），便于工程解释与对比。

---

## 4. 你已经做过的实验与“改进尝试”（科研内容层面）
> 这里总结你在对话中已经明确完成或尝试过的改进方向（不讲具体代码实现）。

### 4.1 基线体系：不止 GBDT
你主动提出“基线是不是可以增加别的”，因此我们讨论过：  
- 仅用 GBDT 作为对照不足够全面；表格任务常见强基线应覆盖：
  - 线性/岭回归/套索（检验可线性解释部分）
  - Random Forest
  - ExtraTrees
  - XGBoost / LightGBM / CatBoost（工业级强基线）
  - 简单 MLP（检验深度但非 Transformer 的因素）
  - FT-Transformer（你主线深度模型）
> 你最终在当前阶段优先把 WP0 与“新增基线实验”落地。

### 4.2 Grid/全组合实验 + 冒烟实验
- 你先跑了“冒烟实验”（例如 epochs=1）确保端到端流程能跑通、产出 summary.csv。
- 你也跑过多组组合（dataset=ideal/perturbed；mode=fm/k_meas/delta_k；model=GBDT/FT；多 seed）。

### 4.3 关键观测：同一套评测，FT 在不同目标空间差异巨大
- 你给出过示例：在某些设置（例如较大 epoch、特定 seed）FT 的 True vs Pred 散点图表现很好。
- 同时你也接受了更“研究化”的解释：  
  **FT 直接回归 FM 易崩是合理现象；在中间量/残差空间学习才是主线。**

### 4.4 你对“成果组织与复现”的改进
你遇到的现实问题：实验跑多了，results 目录堆积，难以辨认哪些有用。  
因此你开始做：
- 结果归档（archive/scratch/keep 等分层思路）
- 统一 summary 表作为“唯一可信来源”
- 清理无用中间产物，保持仓库整洁（这是 WP0 的一部分，而不是琐碎工程活）

---

## 5. summary.csv 是什么、为什么“所有讨论引用同一份表”
你明确问过：**summary.csv 的意义、seed 的影响、为何所有作图/结论都引用同一份表。**  
在你的体系里，summary.csv 的定位应该是：

1) **实验单元的最小可追踪记录（experiment record）**  
   每一行 = 一个配置（dataset/mode/model/seed/超参）跑出来的结果摘要。
2) **让比较不依赖图/日志**  
   - 图可能缺失、日志可能散乱  
   - summary 表可直接用于统计、筛选、聚合、生成论文表格与绘图
3) **让结论可复现可审计**  
   你后续在论文或答辩中所有结论，都可以追溯到某一行 run_id 与对应配置。

> “所有讨论、作图、结论都引用同一份表”的意思：  
> 任何图（比如 R² 分布图、误差箱线图、稳定性散点图）都从 summary.csv 读数据生成；  
> 任何结论（比如“PITT 在 OOD 下更稳”）也必须能在 summary.csv 的统计中复现。

---

## 6. seed 的意义：你为什么要跑多 seed
seed 影响三个层面：
1) **数据切分的随机性**（如果 split 依赖 seed）  
2) **模型训练初始化与批次顺序**（深度模型尤甚）  
3) **评价的稳定性**（你关心的不只是均值，还包括方差/置信区间）

多 seed 的科研价值在于：
- 防止“挑一个好看的 seed 做展示”
- 让方法结论在统计上更可信
- 未来写作时可以报告“均值±标准差”，并做稳定性可视化（你想做的精美图就需要这个）

---

## 7. 有限元仿真（FEA）与你当前残差路线的关系：是否仍有帮助
你提出了两个真实的困惑：
1) 你认为 VDI 合成数据“不保真”，请师兄做仿真来验证；
2) 师兄反馈：仿真难以得到你合成数据那样“很多小数位”的精度；且用“扭矩直接仿真不收敛”，提出用“转角-扭矩关系”替代。

你后来又问：现在你主要预测“残差”而不是 FM，FEA 还是否有用？

在我们对话中形成的关键共识是：
- **FEA 的价值不是提供小数点后一致，而是提供“趋势一致性/偏差结构/可校准残差”的证据**  
- 即便你最终学的是残差（如 \(\Delta k\) 或更一般的偏差项），FEA 仍可提供：
  - 残差的量级范围（是否在合理工程区间）
  - 残差与关键因素的依赖关系（哪些特征导致偏差更大）
  - 用于定义 OOD 或噪声机制变化（WP2 的加分点）
- “转角替代扭矩”是否能达到验证目的：  
  关键看你要验证的是什么：
  - 若验证“解析模型是否系统偏差存在”：可以（转角-扭矩/预紧力映射能体现工艺机理变化）
  - 若验证“数据字段是否一一对应可精确对齐”：可能不行（需要重新定义对齐方式与误差口径）

你当前阶段的现实策略是：
- FEA 结果未到之前，先按主线推进 WP0/WP1 的可复现体系；  
- 等仿真结果到位，再把它纳入“残差结构验证/校准/或 OOD 评测”的模块，而不是推翻现有主线。

---

## 8. 你想要的“论文级精美可视化”是否可行（可行，并且该怎么定位）
你希望做出论文中常见的精美展示（训练/测试对比散点、预测-真实密度对比、稳定性散点等）。  
在我们的讨论语境下，这类图的正确定位是：
- **从 summary.csv 自动生成**（避免手动挑图）
- 支撑 WP2：稳定性、泛化、误差结构、违反率
- 同时服务答辩：把“研究化”讲清楚（不是只有一张好看的散点图）

---

## 9. 你当前进度（对话中已经明确的状态）
1) 你已经把工程推进到“能跑通”的阶段，并完成了若干组合实验（至少包含 ideal/perturbed、fm/k_meas/delta_k、GBDT/FT、若干 seed/epoch 组合）。
2) 你已经开始重视并实施：
   - split 固化（并生成 meta 信息）
   - summary.csv 作为统一记录
   - 结果目录清洁与归档策略
3) 你明确未来主线不是“死磕 FM 直接回归”，而是：
   - **解析先验 + 残差学习（中间量/偏差项）** 的可复现可验证落地

---

## 10. 未来三天/下一阶段你该做什么（科研任务版，不含命令）
> 你曾明确说“我懒得翻上下文，希望直接给我近几天要做的事情”。这里给出科研层面的可执行清单。

### Step A（WP0 收口）：把基准协议完全“写死”
- 固化数据版本：明确以 data/02 为当前 benchmark 数据（并记录字段定义与单位）
- 固化 split：至少 seed=0 作为默认基准；同时准备多 seed 列表用于稳定性评测（例如 0/1/2/3/4 或 40–43 等你已有习惯）
- 固化指标与输出：summary.csv 字段固定；run_id 命名规则固定；确保任意人复现实验都能产出同构表

### Step B（WP0 扩展基线）：把“对照组”做完整
- 在同一协议上跑新增基线（建议至少覆盖：RF / XGBoost 或 LightGBM / 线性基线 / 简单 MLP）
- 统一汇总到同一份 summary.csv（或同格式多文件再合并），形成 baseline leaderboard

### Step C（WP1 启动）：把“残差学习”做成可消融的方法包
- 明确 WP1 的核心预测量：\(\Delta k\) 或等价残差项
- 设计 2–3 个最小消融：
  1) 无残差（纯解析）
  2) 残差但无约束
  3) 残差 + 软约束（或硬约束）
- 每个消融都必须走同一协议、同一评测输出

### Step D（WP2 预埋）：为后续 OOD/可靠性留接口
- 先在 IID 上把多 seed 统计跑通（得到均值±方差）
- 预留 OOD 切分策略（范围外推/组合外推），即便暂时不跑，也要把协议写清楚

---

## 11. 你当前最重要的“研究叙事”（对外表述口径）
你这条路线最能打动评审/答辩的叙事应该是：

1) **问题属性**：VDI2230 解析先验很强，但真实系统存在系统偏差与扰动；只靠黑箱拟合不可信。  
2) **方法主张**：以解析模型为基线，在物理一致空间学习残差（例如 \(\Delta k\)），并引入可行域约束保证物理一致性。  
3) **评测规范**：不仅看 IID 精度，还看 OOD、稳定性、违反率与风险指标。  
4) **交付形态**：形成 benchmark 化、可复现的实验协议与结果追踪体系；后续再扩展 Bolt-BERT 预训练与 Agent 工具闭环。

---

## 12. 备注：你在对话中反复出现的“关键疑问”已得到的定位
- “训练很快是不是科研不够？”  
  → 不看训练时长，看**协议严谨性、对比全面性、可复现性、结论可验证性**。
- “我不懂 WP0/WP1/WP2、软硬约束、消融、split 固化是什么”  
  → 你已把研究推进到需要“研究化组织”的阶段：先固化基准，再做方法，再做鲁棒与可靠。
- “我师兄用转角替代扭矩仿真是否有意义？”  
  → 有意义，但要重新明确“验证目标”（偏差结构/趋势/校准 vs 数值逐点对齐）。

---

## 13. 当前结论（阶段性）
- **GBDT 在解析合成数据上极强**是预期现象，说明任务存在强规则结构；
- **FT-Transformer 直接回归 FM 容易崩**并不否定路线，反而提示应转向“中间量/残差空间 + 物理一致归一化”；
- 你的研究主线已从“做一个工程助手”升级为“提出并验证可复现研究范式”：  
  **PITT（解析先验 + 残差学习 + 约束一致性）+ Benchmark 协议（split/seed/summary）+ 可靠性评测（OOD/稳定性/违反率）**。

---

## 14. 你下一次开新聊天时，建议你直接给助理的最小信息包
1) 你当前使用的数据版本（data/02）  
2) 你当前的默认 split seed（例如 seed=0）与多 seed 列表  
3) 你当前 summary.csv 路径与字段定义  
4) 你当前 WP 阶段（WP0 收口 + 新增基线；准备启动 WP1 残差方法）  
5) 你是否已经拿到 FEA 结果（如果拿到：包含哪些输出量、如何对齐）

（把以上 5 点贴给新对话，助理就能无缝接续。）

---
